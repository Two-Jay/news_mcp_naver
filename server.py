#!/usr/bin/env python3
"""
News MCP Server

A Model Context Protocol (MCP) server that provides access to news articles.
Uses Naver News Search API.
"""

import asyncio
import json
import logging
import os
import re
from pathlib import Path
from typing import Any, Dict, List, Optional
from urllib.parse import quote

import aiohttp
import anthropic
from mcp.server import Server
from mcp.server.models import InitializationOptions
from mcp.server.stdio import stdio_server
from mcp.types import (
    Resource,
    Tool,
    TextContent,
    ImageContent,
    EmbeddedResource,
    LoggingLevel
)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("news-mcp-server")

# Naver News Search API ì„¤ì •
NAVER_API_BASE_URL = "https://openapi.naver.com/v1/search/news.json"


class NewsMCPServer:
    # ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ì •ì˜
    NEWS_CATEGORIES = {
        "politics": {
            "name": "ì •ì¹˜",
            "keywords": ["ì •ì¹˜", "êµ­íšŒ", "ëŒ€í†µë ¹", "ì •ë‹¹", "ì„ ê±°"],
            "description": "ì •ì¹˜, êµ­íšŒ, ì •ë‹¹ ê´€ë ¨ ë‰´ìŠ¤"
        },
        "economy": {
            "name": "ê²½ì œ",
            "keywords": ["ê²½ì œ", "ì£¼ì‹", "ë¶€ë™ì‚°", "ê¸ˆìœµ", "ê¸°ì—…"],
            "description": "ê²½ì œ, ê¸ˆìœµ, ì¦ì‹œ, ë¶€ë™ì‚° ê´€ë ¨ ë‰´ìŠ¤"
        },
        "society": {
            "name": "ì‚¬íšŒ",
            "keywords": ["ì‚¬íšŒ", "ì‚¬ê±´", "ì‚¬ê³ ", "êµìœ¡", "í™˜ê²½"],
            "description": "ì‚¬íšŒ, êµìœ¡, í™˜ê²½, ì‚¬ê±´ì‚¬ê³  ê´€ë ¨ ë‰´ìŠ¤"
        },
        "culture": {
            "name": "ìƒí™œ/ë¬¸í™”",
            "keywords": ["ë¬¸í™”", "ì—¬í–‰", "ìŒì‹", "ê±´ê°•", "íŒ¨ì…˜"],
            "description": "ìƒí™œ, ë¬¸í™”, ì—¬í–‰, ê±´ê°• ê´€ë ¨ ë‰´ìŠ¤"
        },
        "tech": {
            "name": "IT/ê³¼í•™",
            "keywords": ["IT", "ê³¼í•™", "ê¸°ìˆ ", "AI", "ìŠ¤ë§ˆíŠ¸í°"],
            "description": "IT, ê³¼í•™, ê¸°ìˆ , ì¸ê³µì§€ëŠ¥ ê´€ë ¨ ë‰´ìŠ¤"
        },
        "world": {
            "name": "ì„¸ê³„",
            "keywords": ["êµ­ì œ", "ì„¸ê³„", "ë¯¸êµ­", "ì¤‘êµ­", "ì¼ë³¸"],
            "description": "êµ­ì œ, ì„¸ê³„ ê°êµ­ ê´€ë ¨ ë‰´ìŠ¤"
        },
        "sports": {
            "name": "ìŠ¤í¬ì¸ ",
            "keywords": ["ìŠ¤í¬ì¸ ", "ì¶•êµ¬", "ì•¼êµ¬", "ë†êµ¬", "ì˜¬ë¦¼í”½"],
            "description": "ìŠ¤í¬ì¸ , í”„ë¡œì•¼êµ¬, ì¶•êµ¬, ì˜¬ë¦¼í”½ ê´€ë ¨ ë‰´ìŠ¤"
        },
        "entertainment": {
            "name": "ì—°ì˜ˆ",
            "keywords": ["ì—°ì˜ˆ", "ë“œë¼ë§ˆ", "ì˜í™”", "K-POP", "ì•„ì´ëŒ"],
            "description": "ì—°ì˜ˆ, ë“œë¼ë§ˆ, ì˜í™”, K-POP ê´€ë ¨ ë‰´ìŠ¤"
        }
    }
    
    def __init__(self):
        self.app = Server("news-mcp-server")
        self.session: Optional[aiohttp.ClientSession] = None
        
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
        self.client_id = os.environ.get("news_client_id")
        self.client_secret = os.environ.get("news_client_secret")
        
        if not self.client_id or not self.client_secret:
            logger.warning("Naver API credentials not found in environment variables")
        else:
            logger.info("Naver API credentials loaded successfully")
        
        # Claude API í‚¤ ë¡œë“œ
        self.claude_api_key = os.environ.get("claude_api_key")
        self.claude_client: Optional[anthropic.Anthropic] = None
        
        if not self.claude_api_key:
            logger.warning("Claude API key not found in environment variables")
        else:
            self.claude_client = anthropic.Anthropic(api_key=self.claude_api_key)
            logger.info("Claude API client initialized successfully")
        
        # ë‰´ìŠ¤ ìš”ì•½ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        self.summary_prompt = self._load_summary_prompt()
        
        # Register handlers
        self._setup_handlers()
    
    def _load_summary_prompt(self) -> str:
        """news_summary_prompt.md íŒŒì¼ì—ì„œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        prompt_file = Path(__file__).parent / "news_summary_prompt.md"
        try:
            if prompt_file.exists():
                content = prompt_file.read_text(encoding="utf-8")
                logger.info("News summary prompt loaded successfully")
                return content
            else:
                logger.warning(f"Prompt file not found: {prompt_file}")
                return self._get_default_summary_prompt()
        except Exception as e:
            logger.error(f"Error loading prompt file: {e}")
            return self._get_default_summary_prompt()
    
    def _get_default_summary_prompt(self) -> str:
        """ê¸°ë³¸ ë‰´ìŠ¤ ìš”ì•½ í”„ë¡¬í”„íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return """You are a Korean News Analyst & Summarizer. 
Summarize news articles in a compact, readable way.
Prioritize verifiable facts, numbers, and who/what/when outcomes.
Output in Korean with JSON format."""
    
    def _setup_handlers(self):
        """Setup MCP server handlers"""
        
        @self.app.list_resources()
        async def handle_list_resources() -> List[Resource]:
            """List available resources"""
            return [
                Resource(
                    uri="news://search",
                    name="News Search",
                    description="Search for news articles",
                    mimeType="application/json"
                ),
                Resource(
                    uri="news://categories",
                    name="News Categories",
                    description="ì‚¬ìš© ê°€ëŠ¥í•œ ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ëª©ë¡ (Available news categories)",
                    mimeType="application/json"
                )
            ]
        
        @self.app.read_resource()
        async def handle_read_resource(uri: str) -> str:
            """Read a specific resource"""
            if uri == "news://search":
                return json.dumps({
                    "description": "Use the search_news tool to find news articles",
                    "example": "search_news with query='technology'"
                }, ensure_ascii=False)
            elif uri == "news://categories":
                return json.dumps(self._get_categories(), ensure_ascii=False)
            else:
                raise ValueError(f"Unknown resource: {uri}")
        
        @self.app.list_tools()
        async def handle_list_tools() -> List[Tool]:
            """List available tools"""
            # ì¹´í…Œê³ ë¦¬ ID ëª©ë¡ ìƒì„±
            category_ids = list(self.NEWS_CATEGORIES.keys())
            category_desc = ", ".join([f"{k}({v['name']})" for k, v in self.NEWS_CATEGORIES.items()])
            
            return [
                Tool(
                    name="search_news",
                    description="ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤ (Search for news articles by keyword using Naver News API)",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "ê²€ìƒ‰ì–´ (Search query keywords)"
                            },
                            "display": {
                                "type": "integer",
                                "description": "í•œ ë²ˆì— í‘œì‹œí•  ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸ê°’: 10, ìµœëŒ“ê°’: 100)",
                                "default": 10
                            },
                            "start": {
                                "type": "integer",
                                "description": "ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (ê¸°ë³¸ê°’: 1, ìµœëŒ“ê°’: 1000)",
                                "default": 1
                            },
                            "sort": {
                                "type": "string",
                                "enum": ["sim", "date"],
                                "description": "ê²€ìƒ‰ ê²°ê³¼ ì •ë ¬ ë°©ë²• - sim: ì •í™•ë„ìˆœ(ê¸°ë³¸ê°’), date: ë‚ ì§œìˆœ",
                                "default": "sim"
                            }
                        },
                        "required": ["query"]
                    }
                ),
                Tool(
                    name="get_category_news",
                    description=f"íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬: {category_desc}",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "category": {
                                "type": "string",
                                "enum": category_ids,
                                "description": f"ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ID: {category_desc}"
                            },
                            "display": {
                                "type": "integer",
                                "description": "í•œ ë²ˆì— í‘œì‹œí•  ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸ê°’: 10, ìµœëŒ“ê°’: 100)",
                                "default": 10
                            },
                            "sort": {
                                "type": "string",
                                "enum": ["sim", "date"],
                                "description": "ê²€ìƒ‰ ê²°ê³¼ ì •ë ¬ ë°©ë²• - sim: ì •í™•ë„ìˆœ, date: ë‚ ì§œìˆœ(ê¸°ë³¸ê°’)",
                                "default": "date"
                            }
                        },
                        "required": ["category"]
                    }
                ),
                Tool(
                    name="list_categories",
                    description="ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ëª©ë¡ê³¼ ì„¤ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤ (List all available news categories)",
                    inputSchema={
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                ),
                Tool(
                    name="generate_news_report",
                    description="íŠ¹ì • ì£¼ì œì— ëŒ€í•´ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  ì¢…í•©ì ì¸ ë¦¬ì„œì¹˜ ë ˆí¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì—¬ íŠ¸ë Œë“œ, ì£¼ìš” ì´ìŠˆ, í•µì‹¬ ë‚´ìš©ì„ ì •ë¦¬í•œ ë ˆí¬íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "topic": {
                                "type": "string",
                                "description": "ë ˆí¬íŠ¸ë¥¼ ìƒì„±í•  ì£¼ì œ (ì˜ˆ: 'ì¸ê³µì§€ëŠ¥ ì‚°ì—… ë™í–¥', 'ë¶€ë™ì‚° ì‹œì¥', 'ì „ê¸°ì°¨ ì‹œì¥')"
                            },
                            "keywords": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "ì¶”ê°€ ê²€ìƒ‰ í‚¤ì›Œë“œ (ì„ íƒì‚¬í•­, ê¸°ë³¸: ì£¼ì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìë™ ìƒì„±)"
                            },
                            "num_articles": {
                                "type": "integer",
                                "description": "ìˆ˜ì§‘í•  ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ (ê¸°ë³¸ê°’: 15, ìµœëŒ€: 50)",
                                "default": 15
                            },
                            "include_links": {
                                "type": "boolean",
                                "description": "ë ˆí¬íŠ¸ì— ì›ë¬¸ ë§í¬ í¬í•¨ ì—¬ë¶€ (ê¸°ë³¸ê°’: true)",
                                "default": True
                            }
                        },
                        "required": ["topic"]
                    }
                ),
                Tool(
                    name="search_and_summarize_news",
                    description="í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  Claude AIë¥¼ í™œìš©í•˜ì—¬ ì „ë¬¸ì ì¸ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤. ë‰´ìŠ¤ ìœ í˜•(ì‚¬ì‹¤/ë¶„ì„/ì˜ˆì¸¡/í˜¼í•©)ì„ ë¶„ë¥˜í•˜ê³ , í•µì‹¬ íŒ©íŠ¸ì™€ ìˆ˜ì¹˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•©ë‹ˆë‹¤.",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "keywords": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "ê²€ìƒ‰í•  í‚¤ì›Œë“œ ëª©ë¡ (ì˜ˆ: ['AI ë°˜ë„ì²´', 'ì‚¼ì„±ì „ì'])"
                            },
                            "num_articles": {
                                "type": "integer",
                                "description": "í‚¤ì›Œë“œë‹¹ ê²€ìƒ‰í•  ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ (ê¸°ë³¸ê°’: 5, ìµœëŒ€: 10)",
                                "default": 5
                            },
                            "include_keyword_curation": {
                                "type": "boolean",
                                "description": "ê° í‚¤ì›Œë“œë³„ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” 3ê°œ ë‰´ìŠ¤ ì†ŒìŠ¤ íë ˆì´ì…˜ í¬í•¨ ì—¬ë¶€ (ê¸°ë³¸ê°’: true)",
                                "default": True
                            }
                        },
                        "required": ["keywords"]
                    }
                )
            ]
        
        @self.app.call_tool()
        async def handle_call_tool(name: str, arguments: Dict[str, Any]) -> List[TextContent]:
            """Handle tool calls"""
            try:
                if name == "search_news":
                    return await self._search_news(**arguments)
                elif name == "get_category_news":
                    return await self._get_category_news(**arguments)
                elif name == "list_categories":
                    return self._list_categories()
                elif name == "generate_news_report":
                    return await self._generate_news_report(**arguments)
                elif name == "search_and_summarize_news":
                    return await self._search_and_summarize_news(**arguments)
                else:
                    raise ValueError(f"Unknown tool: {name}")
            except Exception as e:
                logger.error(f"Error in tool {name}: {str(e)}")
                return [TextContent(type="text", text=f"Error: {str(e)}")]
    
    async def _ensure_session(self):
        """Ensure we have an active aiohttp session"""
        if self.session is None or self.session.closed:
            self.session = aiohttp.ClientSession()
    
    async def _search_news(
        self, 
        query: str, 
        display: int = 10, 
        start: int = 1, 
        sort: str = "sim"
    ) -> List[TextContent]:
        """
        ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            query: ê²€ìƒ‰ì–´
            display: í•œ ë²ˆì— í‘œì‹œí•  ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸ê°’: 10, ìµœëŒ“ê°’: 100)
            start: ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (ê¸°ë³¸ê°’: 1, ìµœëŒ“ê°’: 1000)
            sort: ì •ë ¬ ë°©ë²• - sim(ì •í™•ë„ìˆœ), date(ë‚ ì§œìˆœ)
        """
        await self._ensure_session()
        
        # API ìê²© ì¦ëª… í™•ì¸
        if not self.client_id or not self.client_secret:
            return [TextContent(
                type="text",
                text="ì˜¤ë¥˜: ë„¤ì´ë²„ API ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                     "í™˜ê²½ ë³€ìˆ˜ news_client_idì™€ news_client_secretì„ ì„¤ì •í•´ì£¼ì„¸ìš”."
            )]
        
        # íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì‚¬
        display = max(1, min(display, 100))  # 1~100
        start = max(1, min(start, 1000))  # 1~1000
        if sort not in ["sim", "date"]:
            sort = "sim"
        
        # ìš”ì²­ í—¤ë” ì„¤ì •
        headers = {
            "X-Naver-Client-Id": self.client_id,
            "X-Naver-Client-Secret": self.client_secret
        }
        
        # ìš”ì²­ íŒŒë¼ë¯¸í„° ì„¤ì •
        params = {
            "query": query,
            "display": display,
            "start": start,
            "sort": sort
        }
        
        try:
            async with self.session.get(
                NAVER_API_BASE_URL,
                headers=headers,
                params=params
            ) as response:
                if response.status != 200:
                    error_text = await response.text()
                    logger.error(f"Naver API error: {response.status} - {error_text}")
                    return [TextContent(
                        type="text",
                        text=f"API ì˜¤ë¥˜ (ìƒíƒœ ì½”ë“œ: {response.status}): {error_text}"
                    )]
                
                data = await response.json()
                return self._format_news_results(data, query)
                
        except aiohttp.ClientError as e:
            logger.error(f"Network error: {str(e)}")
            return [TextContent(
                type="text",
                text=f"ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}"
            )]
    
    def _get_categories(self) -> Dict[str, Any]:
        """ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return {
            "categories": [
                {
                    "id": cat_id,
                    "name": cat_info["name"],
                    "description": cat_info["description"],
                    "sample_keywords": cat_info["keywords"]
                }
                for cat_id, cat_info in self.NEWS_CATEGORIES.items()
            ]
        }
    
    def _list_categories(self) -> List[TextContent]:
        """ì¹´í…Œê³ ë¦¬ ëª©ë¡ì„ í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        lines = [
            "## ğŸ“‚ ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ëª©ë¡",
            "",
            "ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:",
            ""
        ]
        
        for cat_id, cat_info in self.NEWS_CATEGORIES.items():
            lines.append(f"### {cat_info['name']} (`{cat_id}`)")
            lines.append(f"- **ì„¤ëª…:** {cat_info['description']}")
            lines.append(f"- **ê´€ë ¨ í‚¤ì›Œë“œ:** {', '.join(cat_info['keywords'])}")
            lines.append("")
        
        lines.append("---")
        lines.append("ğŸ’¡ **ì‚¬ìš©ë²•:** `get_category_news` ë„êµ¬ì—ì„œ category íŒŒë¼ë¯¸í„°ì— ì¹´í…Œê³ ë¦¬ IDë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        lines.append("ì˜ˆ: `get_category_news(category='tech')` â†’ IT/ê³¼í•™ ë‰´ìŠ¤ ê²€ìƒ‰")
        
        return [TextContent(type="text", text="\n".join(lines))]
    
    async def _get_category_news(
        self,
        category: str,
        display: int = 10,
        sort: str = "date"
    ) -> List[TextContent]:
        """
        íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            category: ì¹´í…Œê³ ë¦¬ ID
            display: í‘œì‹œí•  ê²°ê³¼ ê°œìˆ˜
            sort: ì •ë ¬ ë°©ë²•
        """
        if category not in self.NEWS_CATEGORIES:
            available = ", ".join(self.NEWS_CATEGORIES.keys())
            return [TextContent(
                type="text",
                text=f"ì˜¤ë¥˜: ì•Œ ìˆ˜ ì—†ëŠ” ì¹´í…Œê³ ë¦¬ '{category}'. ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬: {available}"
            )]
        
        cat_info = self.NEWS_CATEGORIES[category]
        # ì¹´í…Œê³ ë¦¬ì˜ ì²« ë²ˆì§¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
        query = cat_info["keywords"][0]
        
        return await self._search_news(
            query=query,
            display=display,
            sort=sort
        )
    
    def _clean_html_tags(self, text: str) -> str:
        """HTML íƒœê·¸ë¥¼ ì œê±°í•©ë‹ˆë‹¤."""
        # <b> íƒœê·¸ ë“± HTML íƒœê·¸ ì œê±°
        clean_text = re.sub(r'<[^>]+>', '', text)
        # HTML ì—”í‹°í‹° ë³€í™˜
        clean_text = clean_text.replace("&quot;", '"')
        clean_text = clean_text.replace("&amp;", '&')
        clean_text = clean_text.replace("&lt;", '<')
        clean_text = clean_text.replace("&gt;", '>')
        clean_text = clean_text.replace("&apos;", "'")
        return clean_text
    
    def _format_news_results(self, data: Dict[str, Any], query: str) -> List[TextContent]:
        """API ì‘ë‹µì„ ì½ê¸° ì¢‹ì€ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
        total = data.get("total", 0)
        start = data.get("start", 1)
        display = data.get("display", 0)
        items = data.get("items", [])
        
        if not items:
            return [TextContent(
                type="text",
                text=f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            )]
        
        result_lines = [
            f"## ğŸ“° '{query}' ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼",
            f"ì´ {total:,}ê°œì˜ ê²°ê³¼ ì¤‘ {start}~{start + len(items) - 1}ë²ˆì§¸ ê²°ê³¼",
            ""
        ]
        
        for i, item in enumerate(items, start):
            title = self._clean_html_tags(item.get("title", "ì œëª© ì—†ìŒ"))
            description = self._clean_html_tags(item.get("description", "ë‚´ìš© ì—†ìŒ"))
            original_link = item.get("originallink", "")
            naver_link = item.get("link", "")
            pub_date = item.get("pubDate", "ì•Œ ìˆ˜ ì—†ìŒ")
            
            result_lines.append(f"### {i}. {title}")
            result_lines.append(f"**ë°œí–‰ì¼:** {pub_date}")
            result_lines.append(f"**ìš”ì•½:** {description}")
            if original_link:
                result_lines.append(f"**ì›ë¬¸ ë§í¬:** {original_link}")
            if naver_link and naver_link != original_link:
                result_lines.append(f"**ë„¤ì´ë²„ ë‰´ìŠ¤:** {naver_link}")
            result_lines.append("")
        
        return [TextContent(type="text", text="\n".join(result_lines))]
    
    async def _generate_news_report(
        self,
        topic: str,
        keywords: Optional[List[str]] = None,
        num_articles: int = 15,
        include_links: bool = True
    ) -> List[TextContent]:
        """
        íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ë‰´ìŠ¤ ë ˆí¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            topic: ë ˆí¬íŠ¸ ì£¼ì œ
            keywords: ì¶”ê°€ ê²€ìƒ‰ í‚¤ì›Œë“œ (ì„ íƒ)
            num_articles: ìˆ˜ì§‘í•  ê¸°ì‚¬ ìˆ˜
            include_links: ë§í¬ í¬í•¨ ì—¬ë¶€
        """
        await self._ensure_session()
        
        # API ìê²© ì¦ëª… í™•ì¸
        if not self.client_id or not self.client_secret:
            return [TextContent(
                type="text",
                text="ì˜¤ë¥˜: ë„¤ì´ë²„ API ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                     "í™˜ê²½ ë³€ìˆ˜ news_client_idì™€ news_client_secretì„ ì„¤ì •í•´ì£¼ì„¸ìš”."
            )]
        
        # íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì‚¬
        num_articles = max(5, min(num_articles, 50))
        
        # ê²€ìƒ‰ í‚¤ì›Œë“œ ì¤€ë¹„ (ì£¼ì œ + ì¶”ê°€ í‚¤ì›Œë“œ)
        search_queries = [topic]
        if keywords:
            search_queries.extend(keywords[:3])  # ìµœëŒ€ 3ê°œì˜ ì¶”ê°€ í‚¤ì›Œë“œ
        
        # ëª¨ë“  ìˆ˜ì§‘ëœ ê¸°ì‚¬ë¥¼ ì €ì¥
        all_articles = []
        seen_titles = set()  # ì¤‘ë³µ ì œê±°ìš©
        
        # ê° í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ ìˆ˜í–‰
        headers = {
            "X-Naver-Client-Id": self.client_id,
            "X-Naver-Client-Secret": self.client_secret
        }
        
        articles_per_query = max(5, num_articles // len(search_queries))
        
        for query in search_queries:
            params = {
                "query": query,
                "display": min(articles_per_query, 100),
                "start": 1,
                "sort": "date"  # ìµœì‹ ìˆœìœ¼ë¡œ ê²€ìƒ‰
            }
            
            try:
                async with self.session.get(
                    NAVER_API_BASE_URL,
                    headers=headers,
                    params=params
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        items = data.get("items", [])
                        
                        for item in items:
                            title = self._clean_html_tags(item.get("title", ""))
                            # ì¤‘ë³µ ì œê±°
                            if title and title not in seen_titles:
                                seen_titles.add(title)
                                all_articles.append({
                                    "title": title,
                                    "description": self._clean_html_tags(item.get("description", "")),
                                    "originallink": item.get("originallink", ""),
                                    "link": item.get("link", ""),
                                    "pubDate": item.get("pubDate", ""),
                                    "search_query": query
                                })
            except aiohttp.ClientError as e:
                logger.error(f"Network error for query '{query}': {str(e)}")
                continue
        
        if not all_articles:
            return [TextContent(
                type="text",
                text=f"'{topic}'ì— ëŒ€í•œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )]
        
        # ìˆ˜ì§‘ëœ ê¸°ì‚¬ ìˆ˜ ì œí•œ
        all_articles = all_articles[:num_articles]
        
        # ë ˆí¬íŠ¸ ìƒì„±
        report = self._build_report(topic, search_queries, all_articles, include_links)
        
        return [TextContent(type="text", text=report)]
    
    async def _search_and_summarize_news(
        self,
        keywords: List[str],
        num_articles: int = 5,
        include_keyword_curation: bool = True
    ) -> List[TextContent]:
        """
        í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  Claude AIë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
        
        Args:
            keywords: ê²€ìƒ‰í•  í‚¤ì›Œë“œ ëª©ë¡
            num_articles: í‚¤ì›Œë“œë‹¹ ê²€ìƒ‰í•  ê¸°ì‚¬ ìˆ˜
            include_keyword_curation: í‚¤ì›Œë“œë³„ íë ˆì´ì…˜ í¬í•¨ ì—¬ë¶€
        """
        await self._ensure_session()
        
        # API ìê²© ì¦ëª… í™•ì¸
        if not self.client_id or not self.client_secret:
            return [TextContent(
                type="text",
                text="ì˜¤ë¥˜: ë„¤ì´ë²„ API ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                     "í™˜ê²½ ë³€ìˆ˜ news_client_idì™€ news_client_secretì„ ì„¤ì •í•´ì£¼ì„¸ìš”."
            )]
        
        if not self.claude_client:
            return [TextContent(
                type="text",
                text="ì˜¤ë¥˜: Claude API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                     "í™˜ê²½ ë³€ìˆ˜ claude_api_keyë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
            )]
        
        # íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì‚¬
        num_articles = max(1, min(num_articles, 10))
        keywords = keywords[:5]  # ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œ
        
        # ê° í‚¤ì›Œë“œë³„ë¡œ ë‰´ìŠ¤ ê²€ìƒ‰
        all_news_data = []
        headers = {
            "X-Naver-Client-Id": self.client_id,
            "X-Naver-Client-Secret": self.client_secret
        }
        
        for keyword in keywords:
            params = {
                "query": keyword,
                "display": num_articles,
                "start": 1,
                "sort": "date"
            }
            
            try:
                async with self.session.get(
                    NAVER_API_BASE_URL,
                    headers=headers,
                    params=params
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        items = data.get("items", [])
                        
                        for idx, item in enumerate(items, 1):
                            all_news_data.append({
                                "id": f"{keyword}_{idx}",
                                "keyword": keyword,
                                "ì œëª©": self._clean_html_tags(item.get("title", "")),
                                "ë³¸ë¬¸": self._clean_html_tags(item.get("description", "")),
                                "link": item.get("originallink", "") or item.get("link", ""),
                                "pubDate": item.get("pubDate", "")
                            })
            except aiohttp.ClientError as e:
                logger.error(f"Network error for keyword '{keyword}': {str(e)}")
                continue
        
        if not all_news_data:
            return [TextContent(
                type="text",
                text=f"ê²€ìƒ‰ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œ: {', '.join(keywords)}"
            )]
        
        # Claude APIë¡œ ìš”ì•½ ìš”ì²­
        try:
            summary_result = await self._summarize_with_claude(
                all_news_data, 
                keywords if include_keyword_curation else None
            )
            return [TextContent(type="text", text=summary_result)]
        except Exception as e:
            logger.error(f"Claude API error: {str(e)}")
            return [TextContent(
                type="text",
                text=f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )]
    
    async def _summarize_with_claude(
        self,
        news_data: List[Dict[str, Any]],
        keywords_for_curation: Optional[List[str]] = None
    ) -> str:
        """Claude APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
        
        # ë‰´ìŠ¤ ë°ì´í„°ë¥¼ Claudeì— ì „ë‹¬í•  í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        news_list = []
        for item in news_data:
            news_list.append({
                "id": item["id"],
                "ì œëª©": item["ì œëª©"],
                "ë³¸ë¬¸": item["ë³¸ë¬¸"]
            })
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±
        user_message_parts = []
        user_message_parts.append("ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ë¶„ì„í•˜ê³  ìš”ì•½í•´ì£¼ì„¸ìš”.\n")
        user_message_parts.append(f"news_list: {json.dumps(news_list, ensure_ascii=False)}\n")
        
        if keywords_for_curation:
            user_message_parts.append(f"\nkeywords: {json.dumps(keywords_for_curation, ensure_ascii=False)}")
        
        user_message = "\n".join(user_message_parts)
        
        # Claude API í˜¸ì¶œ (ë™ê¸° ë°©ì‹ìœ¼ë¡œ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None,
            lambda: self.claude_client.messages.create(
                model="claude-haiku-4-5-20251001",
                max_tokens=20000,
                system=self.summary_prompt,
                messages=[
                    {"role": "user", "content": user_message}
                ]
            )
        )
        
        # ì‘ë‹µ ì¶”ì¶œ
        result_text = response.content[0].text
        
        # ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…
        formatted_result = self._format_summary_result(result_text, news_data)
        
        return formatted_result
    
    def _format_summary_result(
        self,
        claude_response: str,
        original_news: List[Dict[str, Any]]
    ) -> str:
        """Claude ì‘ë‹µì„ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
        from datetime import datetime
        
        lines = [
            "=" * 60,
            "# ğŸ“° AI ë‰´ìŠ¤ ìš”ì•½ ë¦¬í¬íŠ¸",
            "=" * 60,
            "",
            f"**ìƒì„±ì¼ì‹œ:** {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}",
            f"**ë¶„ì„ ê¸°ì‚¬ ìˆ˜:** {len(original_news)}ê°œ",
            "",
            "---",
            "",
            "## ğŸ“‹ Claude AI ë¶„ì„ ê²°ê³¼",
            "",
        ]
        
        # Claude ì‘ë‹µ ì¶”ê°€
        lines.append(claude_response)
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # ì›ë¬¸ ë§í¬ ì„¹ì…˜ ì¶”ê°€
        lines.append("## ğŸ”— ì›ë¬¸ ë§í¬")
        lines.append("")
        
        # í‚¤ì›Œë“œë³„ë¡œ ê·¸ë£¹í™”
        keywords_seen = {}
        for item in original_news:
            keyword = item.get("keyword", "ê¸°íƒ€")
            if keyword not in keywords_seen:
                keywords_seen[keyword] = []
            keywords_seen[keyword].append(item)
        
        for keyword, items in keywords_seen.items():
            lines.append(f"### ğŸ·ï¸ {keyword}")
            for item in items:
                lines.append(f"- [{item['ì œëª©']}]({item['link']})")
                lines.append(f"  ğŸ“… {item['pubDate']}")
            lines.append("")
        
        lines.append("---")
        lines.append("*ë³¸ ìš”ì•½ì€ Claude AIë¥¼ í™œìš©í•˜ì—¬ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*")
        
        return "\n".join(lines)
    
    def _build_report(
        self,
        topic: str,
        search_queries: List[str],
        articles: List[Dict[str, Any]],
        include_links: bool
    ) -> str:
        """ë ˆí¬íŠ¸ ë¬¸ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        from datetime import datetime
        
        lines = [
            "=" * 60,
            f"# ğŸ“Š ë‰´ìŠ¤ ë¦¬ì„œì¹˜ ë ˆí¬íŠ¸: {topic}",
            "=" * 60,
            "",
            f"**ìƒì„±ì¼ì‹œ:** {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}",
            f"**ë¶„ì„ ê¸°ì‚¬ ìˆ˜:** {len(articles)}ê°œ",
            f"**ê²€ìƒ‰ í‚¤ì›Œë“œ:** {', '.join(search_queries)}",
            "",
            "---",
            "",
            "## ğŸ“‹ ë ˆí¬íŠ¸ ê°œìš”",
            "",
            f"ë³¸ ë ˆí¬íŠ¸ëŠ” '{topic}'ì— ê´€í•œ ìµœì‹  ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤.",
            "ì•„ë˜ì—ì„œ ì£¼ìš” ë‰´ìŠ¤ ë‚´ìš©ê³¼ í•µì‹¬ í¬ì¸íŠ¸ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "",
            "---",
            "",
            "## ğŸ“° ì£¼ìš” ë‰´ìŠ¤ ìš”ì•½",
            ""
        ]
        
        # ê¸°ì‚¬ë³„ ìš”ì•½
        for i, article in enumerate(articles, 1):
            lines.append(f"### {i}. {article['title']}")
            lines.append(f"ğŸ“… **ë°œí–‰ì¼:** {article['pubDate']}")
            lines.append(f"")
            lines.append(f"**ë‚´ìš© ìš”ì•½:**")
            lines.append(f"> {article['description']}")
            lines.append(f"")
            
            if include_links:
                if article['originallink']:
                    lines.append(f"ğŸ”— [ì›ë¬¸ ë³´ê¸°]({article['originallink']})")
                if article['link'] and article['link'] != article['originallink']:
                    lines.append(f"ğŸ”— [ë„¤ì´ë²„ ë‰´ìŠ¤]({article['link']})")
            
            lines.append("")
            lines.append("---")
            lines.append("")
        
        # ë ˆí¬íŠ¸ í‘¸í„°
        lines.extend([
            "",
            "---",
            f"*ë³¸ ë ˆí¬íŠ¸ëŠ” ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ APIë¥¼ í†µí•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*"
        ])
        
        return "\n".join(lines)
    
    async def run(self):
        """Run the MCP server"""
        # Setup initialization options
        init_options = InitializationOptions(
            server_name="news-mcp-server",
            server_version="1.0.0",
            capabilities={
                "resources": {},
                "tools": {},
                "prompts": {},
                "logging": {}
            }
        )
        
        async with stdio_server() as (read_stream, write_stream):
            await self.app.run(
                read_stream,
                write_stream,
                init_options
            )


async def main():
    """Main entry point"""
    server = NewsMCPServer()
    await server.run()


if __name__ == "__main__":
    asyncio.run(main())
